
CondaError: Run 'conda init' before 'conda activate'

Starting Job on sg050
GPUs available: 0,1
Starting User Model (Qwen3-32B) on GPU 0...
Starting Agent Model (Qwen3-8B) on GPU 1...
Waiting for servers to start...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
INFO 02-10 16:31:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 02-10 16:31:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=1663686)[0;0m INFO 02-10 16:31:19 [api_server.py:1977] vLLM API server version 0.11.2
[1;36m(APIServer pid=1663685)[0;0m INFO 02-10 16:31:19 [api_server.py:1977] vLLM API server version 0.11.2
[1;36m(APIServer pid=1663686)[0;0m INFO 02-10 16:31:19 [utils.py:253] non-default args: {'model': 'Qwen/Qwen3-8B', 'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 40960, 'swap_space': 16.0}
[1;36m(APIServer pid=1663685)[0;0m INFO 02-10 16:31:19 [utils.py:253] non-default args: {'port': 8001, 'model': 'Qwen/Qwen3-32B', 'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 40960, 'served_model_name': ['User-Qwen3-32B'], 'swap_space': 16.0}
[1;36m(APIServer pid=1663686)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[1;36m(APIServer pid=1663685)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[1;36m(APIServer pid=1663685)[0;0m INFO 02-10 16:31:20 [model.py:631] Resolved architecture: Qwen3ForCausalLM
[1;36m(APIServer pid=1663685)[0;0m WARNING 02-10 16:31:20 [model.py:1971] Casting torch.bfloat16 to torch.float16.
[1;36m(APIServer pid=1663685)[0;0m INFO 02-10 16:31:20 [model.py:1745] Using max model len 40960
[1;36m(APIServer pid=1663686)[0;0m INFO 02-10 16:31:20 [model.py:631] Resolved architecture: Qwen3ForCausalLM
[1;36m(APIServer pid=1663686)[0;0m WARNING 02-10 16:31:20 [model.py:1971] Casting torch.bfloat16 to torch.float16.
[1;36m(APIServer pid=1663686)[0;0m INFO 02-10 16:31:20 [model.py:1745] Using max model len 40960
[1;36m(APIServer pid=1663686)[0;0m INFO 02-10 16:31:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=1663685)[0;0m INFO 02-10 16:31:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:31:31 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-32B', speculative_config=None, tokenizer='Qwen/Qwen3-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=User-Qwen3-32B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:31:31 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-8B', speculative_config=None, tokenizer='Qwen/Qwen3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-8B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:31:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.139.126.50:59989 backend=nccl
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:31:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.139.126.50:41519 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:31:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:31:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:31:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-8B...
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:31:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-32B...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663842)[0;0m /home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
[1;36m(EngineCore_DP0 pid=1663842)[0;0m We recommend installing via `pip install torch-c-dlpack-ext`
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   warnings.warn(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:32:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1663842)[0;0m INFO 02-10 16:32:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 650, in make_layers
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     + [
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 651, in <listcomp>
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m ERROR 02-10 16:32:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 19.50 GiB of which 334.94 MiB is free. Process 1524126 has 966.00 MiB memory in use. Including non-PyTorch memory, this process has 19.10 GiB memory in use. Process 1663850 has 1.47 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 18.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1663842)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 650, in make_layers
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     + [
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/utils.py", line 651, in <listcomp>
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=1663842)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=1663842)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663842)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 19.50 GiB of which 334.94 MiB is free. Process 1524126 has 966.00 MiB memory in use. Including non-PyTorch memory, this process has 19.10 GiB memory in use. Process 1663850 has 1.47 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 18.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W210 16:32:03.738685688 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=1663685)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[1;36m(APIServer pid=1663685)[0;0m     return _run_code(code, main_globals, None,
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/runpy.py", line 86, in _run_code
[1;36m(APIServer pid=1663685)[0;0m     exec(code, run_globals)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2096, in <module>
[1;36m(APIServer pid=1663685)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/uvloop/__init__.py", line 69, in run
[1;36m(APIServer pid=1663685)[0;0m     return loop.run_until_complete(wrapper())
[1;36m(APIServer pid=1663685)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/uvloop/__init__.py", line 48, in wrapper
[1;36m(APIServer pid=1663685)[0;0m     return await main
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2024, in run_server
[1;36m(APIServer pid=1663685)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2043, in run_server_worker
[1;36m(APIServer pid=1663685)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 200, in __aenter__
[1;36m(APIServer pid=1663685)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 195, in build_async_engine_client
[1;36m(APIServer pid=1663685)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 200, in __aenter__
[1;36m(APIServer pid=1663685)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 236, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=1663685)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/utils/func_utils.py", line 116, in inner
[1;36m(APIServer pid=1663685)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 203, in from_vllm_config
[1;36m(APIServer pid=1663685)[0;0m     return cls(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 133, in __init__
[1;36m(APIServer pid=1663685)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 121, in make_async_mp_client
[1;36m(APIServer pid=1663685)[0;0m     return AsyncMPClient(*client_args)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 808, in __init__
[1;36m(APIServer pid=1663685)[0;0m     super().__init__(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 469, in __init__
[1;36m(APIServer pid=1663685)[0;0m     with launch_core_engines(vllm_config, executor_class, log_stats) as (
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 143, in __exit__
[1;36m(APIServer pid=1663685)[0;0m     next(self.gen)
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 907, in launch_core_engines
[1;36m(APIServer pid=1663685)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=1663685)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 964, in wait_for_engine_startup
[1;36m(APIServer pid=1663685)[0;0m     raise RuntimeError(
[1;36m(APIServer pid=1663685)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
[1;36m(EngineCore_DP0 pid=1663850)[0;0m /home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
[1;36m(EngineCore_DP0 pid=1663850)[0;0m We recommend installing via `pip install torch-c-dlpack-ext`
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   warnings.warn(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:06<00:27,  6.89s/it]
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:14<00:21,  7.16s/it]
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:21<00:14,  7.05s/it]
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:22<00:04,  4.80s/it]
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:29<00:00,  5.51s/it]
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:29<00:00,  5.86s/it]
[1;36m(EngineCore_DP0 pid=1663850)[0;0m 
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:37 [default_loader.py:314] Loading weights took 29.39 seconds
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:38 [gpu_model_runner.py:3338] Model loading took 15.2683 GiB memory and 62.116746 seconds
Waiting for User Model...
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:52 [backends.py:631] Using cache directory: /scratch/svijay46/xdg_cache/vllm/torch_compile_cache/a78dc14a64/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:52 [backends.py:647] Dynamo bytecode transform time: 13.76 s
[1;36m(EngineCore_DP0 pid=1663850)[0;0m [rank0]:W0210 16:32:53.635000 1663850 site-packages/torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:32:59 [backends.py:251] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:33:08 [backends.py:282] Compiling a graph for dynamic shape takes 15.38 s
Waiting for User Model...
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:33:10 [monitor.py:34] torch.compile takes 29.14 s in total
[1;36m(EngineCore_DP0 pid=1663850)[0;0m INFO 02-10 16:33:13 [gpu_worker.py:359] Available KV cache memory: 0.84 GiB
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 239, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     kv_cache_configs = get_kv_cache_configs(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/core/kv_cache_utils.py", line 1277, in get_kv_cache_configs
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     check_enough_kv_cache_memory(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/core/kv_cache_utils.py", line 707, in check_enough_kv_cache_memory
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ERROR 02-10 16:33:13 [core.py:842] ValueError: To serve at least one request with the models's max seq len (40960), (5.62 GiB KV cache is needed, which is larger than the available KV cache memory (0.84 GiB). Based on the available memory, the estimated maximum model length is 6112. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1663850)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 239, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     kv_cache_configs = get_kv_cache_configs(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/core/kv_cache_utils.py", line 1277, in get_kv_cache_configs
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     check_enough_kv_cache_memory(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/core/kv_cache_utils.py", line 707, in check_enough_kv_cache_memory
[1;36m(EngineCore_DP0 pid=1663850)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=1663850)[0;0m ValueError: To serve at least one request with the models's max seq len (40960), (5.62 GiB KV cache is needed, which is larger than the available KV cache memory (0.84 GiB). Based on the available memory, the estimated maximum model length is 6112. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.
[rank0]:[W210 16:33:14.536836366 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=1663686)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[1;36m(APIServer pid=1663686)[0;0m     return _run_code(code, main_globals, None,
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/runpy.py", line 86, in _run_code
[1;36m(APIServer pid=1663686)[0;0m     exec(code, run_globals)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2096, in <module>
[1;36m(APIServer pid=1663686)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/uvloop/__init__.py", line 69, in run
[1;36m(APIServer pid=1663686)[0;0m     return loop.run_until_complete(wrapper())
[1;36m(APIServer pid=1663686)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/uvloop/__init__.py", line 48, in wrapper
[1;36m(APIServer pid=1663686)[0;0m     return await main
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2024, in run_server
[1;36m(APIServer pid=1663686)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2043, in run_server_worker
[1;36m(APIServer pid=1663686)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 200, in __aenter__
[1;36m(APIServer pid=1663686)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 195, in build_async_engine_client
[1;36m(APIServer pid=1663686)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 200, in __aenter__
[1;36m(APIServer pid=1663686)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 236, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=1663686)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/utils/func_utils.py", line 116, in inner
[1;36m(APIServer pid=1663686)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 203, in from_vllm_config
[1;36m(APIServer pid=1663686)[0;0m     return cls(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 133, in __init__
[1;36m(APIServer pid=1663686)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 121, in make_async_mp_client
[1;36m(APIServer pid=1663686)[0;0m     return AsyncMPClient(*client_args)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 808, in __init__
[1;36m(APIServer pid=1663686)[0;0m     super().__init__(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 469, in __init__
[1;36m(APIServer pid=1663686)[0;0m     with launch_core_engines(vllm_config, executor_class, log_stats) as (
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 143, in __exit__
[1;36m(APIServer pid=1663686)[0;0m     next(self.gen)
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 907, in launch_core_engines
[1;36m(APIServer pid=1663686)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=1663686)[0;0m   File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 964, in wait_for_engine_startup
[1;36m(APIServer pid=1663686)[0;0m     raise RuntimeError(
[1;36m(APIServer pid=1663686)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Waiting for User Model...
Timeout waiting for User Model
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Waiting for Agent Model...
Timeout waiting for Agent Model
Running Experiments...
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/react/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/react/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/react/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/react/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/react/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/act/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/act/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/act/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/act/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/act/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/fc/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/fc/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/fc/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/fc/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='retail', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/retail/Qwen_Qwen3-8B/fc/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 19, in get_env
    return MockRetailDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/retail/env.py", line 30, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/react/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/react/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/react/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/react/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='react', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/react/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/act/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/act/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/act/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/act/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='act', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/act/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/fc/trial_0', max_concurrency=1, seed=0, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/fc/trial_1', max_concurrency=1, seed=1, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/fc/trial_2', max_concurrency=1, seed=2, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/fc/trial_3', max_concurrency=1, seed=3, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Namespace(num_trials=1, env='airline', model='Qwen/Qwen3-8B', model_provider='openai', user_model='User-Qwen3-32B', user_model_provider='openai', agent_strategy='tool-calling', temperature=0.0, task_split='test', start_index=0, end_index=-1, task_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], log_dir='results/phase1/airline/Qwen_Qwen3-8B/fc/trial_4', max_concurrency=1, seed=4, shuffle=0, user_strategy='llm', few_shot_displays_path=None)
Loading user with strategy: llm

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1002, in request
    response = self._client.send(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/contextlib.py", line 154, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 762, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 690, in completion
    ) = self.make_sync_openai_chat_completion_request(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/logging_utils.py", line 237, in sync_wrapper
    result = func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 502, in make_sync_openai_chat_completion_request
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 477, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1294, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/openai/_base_client.py", line 1034, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2519, in completion
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 2491, in completion
    response = openai_chat_completions.completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/llms/openai/openai.py", line 773, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Connection error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 102, in <module>
    main()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/run.py", line 98, in main
    run(config)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/run.py", line 35, in run
    env = get_env(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/__init__.py", line 29, in get_env
    return MockAirlineDomainEnv(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/airline/env.py", line 26, in __init__
    super().__init__(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/base.py", line 73, in __init__
    self.user = load_user(
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 357, in load_user
    return LLMUserSimulationEnv(model=model, provider=provider)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 58, in __init__
    self.reset()
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 95, in reset
    return self.generate_next_message(self.messages)
  File "/home/svijay46/agents/TLDR_AGENTIC_AI/cse598_project/phase1/tau_bench/envs/user.py", line 61, in generate_next_message
    res = completion(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1740, in wrapper
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/utils.py", line 1561, in wrapper
    result = original_function(*args, **kwargs)
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/main.py", line 4230, in completion
    raise exception_type(
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "/home/svijay46/.conda/envs/tau-bench/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 554, in exception_type
    raise InternalServerError(
litellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=react, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/react/trial_0/*.json
Found 21 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 1 tasks: ['115']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/react/trial_0', '--task-ids', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=react, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/react/trial_1/*.json
Found 13 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 45 tasks: ['71', '72', '73', '74', '75']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/react/trial_1', '--task-ids', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=react, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/react/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/react/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=react, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/react/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/react/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=react, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/react/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/react/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=act, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/act/trial_0/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/act/trial_0', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=act, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/act/trial_1/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/act/trial_1', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=act, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/act/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/act/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=act, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/act/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/act/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=act, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/act/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/act/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/fc/trial_0/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/fc/trial_0', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/fc/trial_1/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/fc/trial_1', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/fc/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/fc/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/fc/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/fc/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=retail, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/retail/Qwen_Qwen3-8B/fc/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'retail', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/retail/Qwen_Qwen3-8B/fc/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=react, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/react/trial_0/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/react/trial_0', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=react, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/react/trial_1/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/react/trial_1', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=react, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/react/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/react/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=react, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/react/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/react/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=react, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/react/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'react', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/react/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=act, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/act/trial_0/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/act/trial_0', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=act, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/act/trial_1/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/act/trial_1', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=act, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/act/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/act/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=act, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/act/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/act/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=act, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/act/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'act', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/act/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=0, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/fc/trial_0/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '0', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/fc/trial_0', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=1, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/fc/trial_1/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '1', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/fc/trial_1', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=2, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/fc/trial_2/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '2', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/fc/trial_2', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=3, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/fc/trial_3/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '3', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/fc/trial_3', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Running Experiment: Domain=airline, Model=Qwen/Qwen3-8B, Strategy=fc, Trial=4, ResumeFrom=0
Scanning for completed tasks in: results/phase1/airline/Qwen_Qwen3-8B/fc/trial_4/*.json
Found 0 log files.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

Warning: Could not determine total tasks (litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.). Falling back to simple start-index.
Resuming/Retrying 116 tasks: ['0', '1', '2', '3', '4']...
Experiment failed with error: Command '['/home/svijay46/.conda/envs/tau-bench/bin/python', 'run.py', '--agent-strategy', 'tool-calling', '--env', 'airline', '--model', 'Qwen/Qwen3-8B', '--model-provider', 'openai', '--user-model', 'User-Qwen3-32B', '--user-model-provider', 'openai', '--user-strategy', 'llm', '--max-concurrency', '1', '--seed', '4', '--log-dir', 'results/phase1/airline/Qwen_Qwen3-8B/fc/trial_4', '--task-ids', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115']' returned non-zero exit status 1.
Experiments Completed!
Stopping vLLM servers...
